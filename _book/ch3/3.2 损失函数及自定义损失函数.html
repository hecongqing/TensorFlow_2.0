
<!DOCTYPE HTML>
<html lang="zh-hans" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>3.2 损失函数及自定义损失函数 · Tensorflow 2.0实战笔记</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        <meta name="author" content="hecongqing">
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="3.3 优化器及自定义优化器.html" />
    
    
    <link rel="prev" href="3.1 自定义模型层.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="输入并搜索" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Tensorflow 2.0 实战笔记
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <span>
            
                    
                    第一章 Tensorflow 2.0入门
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../ch1/tensorflow简介.html">
            
                <a href="../ch1/tensorflow简介.html">
            
                    
                    1.1 Tensorflow简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2" >
            
                <span>
            
                    
                    1.2 Tensorflow安装
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.2.1" data-path="../ch1/Windows下安装.html">
            
                <a href="../ch1/Windows下安装.html">
            
                    
                    1.2.1 Windows下安装
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.2" data-path="../ch1/Ubuntu下安装.html">
            
                <a href="../ch1/Ubuntu下安装.html">
            
                    
                    1.2.2 Ubuntu下安装
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.3" >
            
                <span>
            
                    
                    1.2.3 环境测试
            
                </span>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.3" >
            
                <span>
            
                    
                    1.3 Tensorflow1.x 和2.x接口区别
            
                </span>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    第二章 Tensorflow基础篇 I
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../ch2/张量与操作.html">
            
                <a href="../ch2/张量与操作.html">
            
                    
                    2.1 张量与操作
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../ch2/三种建模方式.html">
            
                <a href="../ch2/三种建模方式.html">
            
                    
                    2.2 三种定义模型方式
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="../ch2/模型训练.html">
            
                <a href="../ch2/模型训练.html">
            
                    
                    2.3 两种模型训练方式
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../ch2/计算图机制.html">
            
                <a href="../ch2/计算图机制.html">
            
                    
                    2.4 计算图机制
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.5" data-path="../ch2/模型保存与加载.html">
            
                <a href="../ch2/模型保存与加载.html">
            
                    
                    2.5 模型保存与加载
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.6" data-path="../ch2/注意.html">
            
                <a href="../ch2/注意.html">
            
                    
                    注意
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.7" data-path="../ch2/注意.html">
            
                <a href="../ch2/注意.html">
            
                    
                    相关bug详解
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" >
            
                <span>
            
                    
                    第三章 Tensorflow基础篇 II
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="3.1 自定义模型层.html">
            
                <a href="3.1 自定义模型层.html">
            
                    
                    3.1 自定义模型层
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.4.2" data-path="3.2 损失函数及自定义损失函数.html">
            
                <a href="3.2 损失函数及自定义损失函数.html">
            
                    
                    3.2 损失函数及自定义损失函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="3.3 优化器及自定义优化器.html">
            
                <a href="3.3 优化器及自定义优化器.html">
            
                    
                    3.3 优化器及自定义优化器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.4" data-path="3.4 评估函数及自定义评估函数.html">
            
                <a href="3.4 评估函数及自定义评估函数.html">
            
                    
                    3.4 评估函数及自定义评估函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.5" data-path="3.5 激活函数及自定义激活函数.html">
            
                <a href="3.5 激活函数及自定义激活函数.html">
            
                    
                    3.5 激活函数及自定义激活函数
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.6" data-path="3.6 Tensorboard使用.html">
            
                <a href="3.6 Tensorboard使用.html">
            
                    
                    3.6 Tensorboard使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.7" data-path="3.7 注意.html">
            
                <a href="3.7 注意.html">
            
                    
                    注意
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.5" >
            
                <span>
            
                    
                    第四章 Tensorflow数据管道
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.5.1" data-path="../ch4/tf.data简介.html">
            
                <a href="../ch4/tf.data简介.html">
            
                    
                    4.1 tf.data简介
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.2" data-path="../ch4/Dataset使用.html">
            
                <a href="../ch4/Dataset使用.html">
            
                    
                    4.2 Dataset使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.3" data-path="../ch4/TFrecord使用.html">
            
                <a href="../ch4/TFrecord使用.html">
            
                    
                    4.3 TFrecord使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.5.4" data-path="../ch4/注意.html">
            
                <a href="../ch4/注意.html">
            
                    
                    注意
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.6" >
            
                <span>
            
                    
                    第五章 卷积神经网络
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.6.1" data-path="../ch5/浅谈卷积神经网络.html">
            
                <a href="../ch5/浅谈卷积神经网络.html">
            
                    
                    5.1 浅谈卷积神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.2" data-path="../ch5/拆解卷积层.html">
            
                <a href="../ch5/拆解卷积层.html">
            
                    
                    5.2 拆解卷积层
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.3" data-path="../ch5/拆解池化层.html">
            
                <a href="../ch5/拆解池化层.html">
            
                    
                    5.3 拆解池化层
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.4" data-path="../ch5/实战1.html">
            
                <a href="../ch5/实战1.html">
            
                    
                    5.4 实战三：Quick, Draw! Google涂鸦识别挑战项目
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.6.5" data-path="../ch4/注意.html">
            
                <a href="../ch4/注意.html">
            
                    
                    注意
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.7" >
            
                <span>
            
                    
                    第六章 循环神经网络
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.7.1" data-path="../ch6/6.1-浅谈循环神经网络.html">
            
                <a href="../ch6/6.1-浅谈循环神经网络.html">
            
                    
                    6.1-浅谈循环神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.2" data-path="../ch6/6.2-word2vec简介及词向量构建.html">
            
                <a href="../ch6/6.2-word2vec简介及词向量构建.html">
            
                    
                    6.2-word2vec简介及词向量构建
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.7.3" data-path="../ch6/6.3-实战四：LSTM实现新闻分类算法.html">
            
                <a href="../ch6/6.3-实战四：LSTM实现新闻分类算法.html">
            
                    
                    6.3-实战四：LSTM实现新闻分类算法
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.8" >
            
                <span>
            
                    
                    第七章 Transorformer网络
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.8.1" data-path="../ch7/7.1-Transfomer原理详解.html">
            
                <a href="../ch7/7.1-Transfomer原理详解.html">
            
                    
                    7.1-Transfromer原理详解
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.8.2" data-path="../ch7/7.2-实战五：Transformer实现英译中机器翻译.html">
            
                <a href="../ch7/7.2-实战五：Transformer实现英译中机器翻译.html">
            
                    
                    7.2-实战五：Transformer实现英译中机器翻译
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.9" >
            
                <span>
            
                    
                    第八章 tf.hub初探
            
                </span>
            

            
        </li>
    
        <li class="chapter " data-level="1.10" >
            
                <span>
            
                    
                    第九章 Tensorflo7部署
            
                </span>
            

            
        </li>
    
        <li class="chapter " data-level="1.11" >
            
                <span>
            
                    
                    第九章 相许Tensorflow
            
                </span>
            

            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            本书使用 GitBook 发布
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >3.2 损失函数及自定义损失函数</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <pre><code class="lang-python">tf.keras.losses.BinaryCrossentropy(
    from_logits=<span class="hljs-keyword">False</span>, label_smoothing=<span class="hljs-number">0</span>, reduction=losses_utils.ReductionV2.AUTO,
    name=<span class="hljs-string">&apos;binary_crossentropy&apos;</span>
)
</code></pre>
<p>&#x53C2;&#x6570;<code>from_logits</code>&#x7684;&#x4F5C;&#x7528;&#xFF1A;&#x6A21;&#x578B;&#x7684;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x6CA1;&#x6709;&#x901A;&#x8FC7;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x65F6;&#xFF0C;&#x5219;&#x9700;&#x8981;&#x4F7F;&#x5F97;<code>from_logits=True</code>&#xFF1B;&#x53CD;&#x4E4B;&#xFF0C;&#x5982;&#x679C;&#x6A21;&#x578B;&#x7684;&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x901A;&#x8FC7;&#x6FC0;&#x6D3B;&#x51FD;&#x6570;&#x540E;&#xFF0C;&#x5219;&#x9700;&#x8981;&#x4F7F;&#x5F97;<code>from_logits=False</code>&#x3002;</p>
<p>&#x539F;&#x7406;&#x662F;&#x4EC0;&#x4E48;&#x5462;&#xFF1F;&#x5F53;&#x4F60;&#x6253;&#x5F00;tensorflow&#x7684;&#x6E90;&#x7801;&#x65F6;&#xFF0C;&#x4E00;&#x5207;&#x90FD;&#x660E;&#x767D;&#x4E86;&#xFF01;</p>
<p>&#x4E0B;&#x9762;&#x8FD9;&#x6BB5;&#x4EE3;&#x7801;&#x6765;&#x6E90;&#x4E8E;<a href="https://github.com/tensorflow/tensorflow/blob/64c3d382cadf7bbe8e7e99884bede8284ff67f56/tensorflow/python/keras/backend.py#L4559" target="_blank">https://github.com/tensorflow/tensorflow/blob/64c3d382cadf7bbe8e7e99884bede8284ff67f56/tensorflow/python/keras/backend.py#L4559</a></p>
<p><code>if not from_logits:</code>&#x8FD9;&#x4E2A;&#x5224;&#x65AD;&#x8BED;&#x53E5;&#x540E;&#xFF0C;&#x5219;&#x4F1A;&#x76F4;&#x63A5;&#x9636;&#x6BB5;bce (binary_crossentropy)&#xFF1B;&#x53CD;&#x4E4B;&#xFF0C;&#x5219;&#x4F1A;&#x8BA1;&#x7B97;<code>nn.sigmoid_cross_entropy_with_logits</code>&#x3002;</p>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">binary_crossentropy</span><span class="hljs-params">(target, output, from_logits=False)</span>:</span>
  <span class="hljs-string">&quot;&quot;&quot;Binary crossentropy between an output tensor and a target tensor.
  Arguments:
      target: A tensor with the same shape as `output`.
      output: A tensor.
      from_logits: Whether `output` is expected to be a logits tensor.
          By default, we consider that `output`
          encodes a probability distribution.
  Returns:
      A tensor.
  &quot;&quot;&quot;</span>
  <span class="hljs-keyword">if</span> <span class="hljs-keyword">not</span> from_logits:
    <span class="hljs-keyword">if</span> (isinstance(output, (ops.EagerTensor, variables_module.Variable)) <span class="hljs-keyword">or</span>
        output.op.type != <span class="hljs-string">&apos;Sigmoid&apos;</span>):
      epsilon_ = _constant_to_tensor(epsilon(), output.dtype.base_dtype)
      output = clip_ops.clip_by_value(output, epsilon_, <span class="hljs-number">1.</span> - epsilon_)

      <span class="hljs-comment"># Compute cross entropy from probabilities.</span>
      bce = target * math_ops.log(output + epsilon())
      bce += (<span class="hljs-number">1</span> - target) * math_ops.log(<span class="hljs-number">1</span> - output + epsilon())
      <span class="hljs-keyword">return</span> -bce
    <span class="hljs-keyword">else</span>:
      <span class="hljs-comment"># When sigmoid activation function is used for output operation, we</span>
      <span class="hljs-comment"># use logits from the sigmoid function directly to compute loss in order</span>
      <span class="hljs-comment"># to prevent collapsing zero when training.</span>
      <span class="hljs-keyword">assert</span> len(output.op.inputs) == <span class="hljs-number">1</span>
      output = output.op.inputs[<span class="hljs-number">0</span>]
  <span class="hljs-keyword">return</span> nn.sigmoid_cross_entropy_with_logits(labels=target, logits=output)
</code></pre>
<p>&#x4E0B;&#x9762;&#x6211;&#x4EEC;&#x518D;&#x5206;&#x6790;&#x4E0B;<code>nn.sigmoid_cross_entropy_with_logits</code>:</p>
<p>&#x4E0B;&#x9762;&#x4EE3;&#x7801;&#x6765;&#x6E90;&#x4E8E; <a href="https://github.com/tensorflow/tensorflow/blob/64c3d382cadf7bbe8e7e99884bede8284ff67f56/tensorflow/python/ops/nn_impl.py#L112" target="_blank">https://github.com/tensorflow/tensorflow/blob/64c3d382cadf7bbe8e7e99884bede8284ff67f56/tensorflow/python/ops/nn_impl.py#L112</a></p>
<p>&#x63A8;&#x5BFC;&#x8FC7;&#x7A0B;&#x5982;&#x4E0B;&#x6240;&#x793A;&#xFF1A;</p>
<pre><code class="lang-reStructuredText"> For brevity, let `x = logits`, `z = labels`.  The logistic loss is
        z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))
      = z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))
      = z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))
      = z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))
      = (1 - z) * x + log(1 + exp(-x))
      = x - x * z + log(1 + exp(-x))
  For x &lt; 0, to avoid overflow in exp(-x), we reformulate the above
        x - x * z + log(1 + exp(-x))
      = log(exp(x)) - x * z + log(1 + exp(-x))
      = - x * z + log(1 + exp(x))
  Hence, to ensure stability and avoid overflow, the implementation uses this
  equivalent formulation
      max(x, 0) - x * z + log(1 + exp(-abs(x)))
  `logits` and `labels` must have the same type and shape.
</code></pre>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">sigmoid_cross_entropy_with_logits</span><span class="hljs-params">(  # pylint: disable=invalid-name
    _sentinel=None,
    labels=None,
    logits=None,
    name=None)</span>:</span>
  <span class="hljs-string">&quot;&quot;&quot;Computes sigmoid cross entropy given `logits`.
  Measures the probability error in discrete classification tasks in which each
  class is independent and not mutually exclusive.  For instance, one could
  perform multilabel classification where a picture can contain both an elephant
  and a dog at the same time.
  For brevity, let `x = logits`, `z = labels`.  The logistic loss is
        z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))
      = z * -log(1 / (1 + exp(-x))) + (1 - z) * -log(exp(-x) / (1 + exp(-x)))
      = z * log(1 + exp(-x)) + (1 - z) * (-log(exp(-x)) + log(1 + exp(-x)))
      = z * log(1 + exp(-x)) + (1 - z) * (x + log(1 + exp(-x))
      = (1 - z) * x + log(1 + exp(-x))
      = x - x * z + log(1 + exp(-x))
  For x &lt; 0, to avoid overflow in exp(-x), we reformulate the above
        x - x * z + log(1 + exp(-x))
      = log(exp(x)) - x * z + log(1 + exp(-x))
      = - x * z + log(1 + exp(x))
  Hence, to ensure stability and avoid overflow, the implementation uses this
  equivalent formulation
      max(x, 0) - x * z + log(1 + exp(-abs(x)))
  `logits` and `labels` must have the same type and shape.
  Args:
    _sentinel: Used to prevent positional parameters. Internal, do not use.
    labels: A `Tensor` of the same type and shape as `logits`.
    logits: A `Tensor` of type `float32` or `float64`.
    name: A name for the operation (optional).
  Returns:
    A `Tensor` of the same shape as `logits` with the componentwise
    logistic losses.
  Raises:
    ValueError: If `logits` and `labels` do not have the same shape.
  &quot;&quot;&quot;</span>
  <span class="hljs-comment"># pylint: disable=protected-access</span>
  nn_ops._ensure_xent_args(<span class="hljs-string">&quot;sigmoid_cross_entropy_with_logits&quot;</span>, _sentinel,
                           labels, logits)
  <span class="hljs-comment"># pylint: enable=protected-access</span>

  <span class="hljs-keyword">with</span> ops.name_scope(name, <span class="hljs-string">&quot;logistic_loss&quot;</span>, [logits, labels]) <span class="hljs-keyword">as</span> name:
    logits = ops.convert_to_tensor(logits, name=<span class="hljs-string">&quot;logits&quot;</span>)
    labels = ops.convert_to_tensor(labels, name=<span class="hljs-string">&quot;labels&quot;</span>)
    <span class="hljs-keyword">try</span>:
      labels.get_shape().merge_with(logits.get_shape())
    <span class="hljs-keyword">except</span> ValueError:
      <span class="hljs-keyword">raise</span> ValueError(<span class="hljs-string">&quot;logits and labels must have the same shape (%s vs %s)&quot;</span> %
                       (logits.get_shape(), labels.get_shape()))

    <span class="hljs-comment"># The logistic loss formula from above is</span>
    <span class="hljs-comment">#   x - x * z + log(1 + exp(-x))</span>
    <span class="hljs-comment"># For x &lt; 0, a more numerically stable formula is</span>
    <span class="hljs-comment">#   -x * z + log(1 + exp(x))</span>
    <span class="hljs-comment"># Note that these two expressions can be combined into the following:</span>
    <span class="hljs-comment">#   max(x, 0) - x * z + log(1 + exp(-abs(x)))</span>
    <span class="hljs-comment"># To allow computing gradients at zero, we define custom versions of max and</span>
    <span class="hljs-comment"># abs functions.</span>
    zeros = array_ops.zeros_like(logits, dtype=logits.dtype)
    cond = (logits &gt;= zeros)
    relu_logits = array_ops.where(cond, logits, zeros)
    neg_abs_logits = array_ops.where(cond, -logits, logits)
    <span class="hljs-keyword">return</span> math_ops.add(
        relu_logits - logits * labels,
        math_ops.log1p(math_ops.exp(neg_abs_logits)),
        name=name)
</code></pre>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="3.1 自定义模型层.html" class="navigation navigation-prev " aria-label="Previous page: 3.1 自定义模型层">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="3.3 优化器及自定义优化器.html" class="navigation navigation-next " aria-label="Next page: 3.3 优化器及自定义优化器">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"3.2 损失函数及自定义损失函数","level":"1.4.2","depth":2,"next":{"title":"3.3 优化器及自定义优化器","level":"1.4.3","depth":2,"path":"ch3/3.3 优化器及自定义优化器.md","ref":"ch3/3.3 优化器及自定义优化器.md","articles":[]},"previous":{"title":"3.1 自定义模型层","level":"1.4.1","depth":2,"path":"ch3/3.1 自定义模型层.md","ref":"ch3/3.1 自定义模型层.md","articles":[]},"dir":"ltr"},"config":{"plugins":["mathjax","livereload"],"root":".","styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"pluginsConfig":{"prism":{"css":["prismjs/themes/prism-solarizedlight.css"]},"livereload":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"fontsettings":{"theme":"white","family":"sans","size":2},"highlight":{},"mathjax":{"forceSVG":false,"version":"2.6-latest"},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"theme":"default","author":"hecongqing","pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"variables":{},"title":"Tensorflow 2.0实战笔记","language":"zh-hans","output.name":"site","gitbook":"3.2.3","description":"记录Tensorflow 2.0遇到的坑"},"file":{"path":"ch3/3.2 损失函数及自定义损失函数.md","mtime":"2020-06-11T05:35:16.888Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2020-09-16T07:33:43.779Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="https://cdn.mathjax.org/mathjax/2.6-latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-mathjax/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

