# 卷积神经网络

卷积神经网络 (Convolutional Neural Networks (CNNs / ConvNets)) 与上一章中的普通神经网络非常相似：它们由具有可学习的权重和偏见的神经元组成。每个神经元接收一些输入，执行点积，并可选地跟随其非线性。整个网络仍然表示一个可区分的分数函数：从一端的原始图像像素到另一端的类分数。而且它们在最后一层（完全连接的）上仍然具有丢失功能（例如SVM / Softmax），并且我们为学习常规神经网络而开发的所有技巧/窍门仍然适用。

那有什么变化呢？ConvNet架构明确假设输入是图像，这使我们可以将某些属性编码到架构中。这些使前向传播函数更有效地实现，并大大减少了网络中的参数数量。

## 架构概述

回想一下：常规神经网络。如上一章所述，神经网络接收输入（单个向量），并通过一系列**隐藏层**对其进行转换。每个隐藏层都由一组神经元组成，其中每个神经元都完全连接到上一层中的所有神经元，并且其中单个层中的神经元完全独立地起作用，并且不共享任何连接。最后一个完全连接的层称为“输出层”，在分类任务中，它表示类别的概率。

常规神经网络无法很好地缩放为完整图像。在CIFAR-10中，图片的尺寸仅为 32x32x3（宽32，高32，RGB通道3），因此，常规神经网络的第一个隐藏层中的单个完全连接的神经元将具有32 * 32 * 3 = 3072的权重。这个数量似乎仍然可以控制，但是很明显，这种完全连接的结构无法缩放到更大的图像。例如，尺寸更大的图像，例如 200x200x3，将导致神经元的权重为200 * 200 * 3 = 120,000。而且，几乎可以肯定，我们希望拥有多个这样的神经元，因此这些参数很快就会加起来！显然，这种全连接方式是浪费的，大量的参数将很快导致过拟合。



神经元的3D体积。卷积神经网络利用了输入由图像组成的事实，并且它们以更明智的方式约束了体系结构。特别是，与常规神经网络不同，ConvNet的各层神经元排列成3个维度：宽度，高度，深度。（请注意，这里的“深度”一词指的是激活体积的第三维，而不是指整个神经网络的深度，后者可以指网络中的总层数。）例如，CIFAR-10中的输入图像是激活的输入体积，并且该体积的尺寸为32x32x3（分别为宽度，高度，深度）。正如我们将很快看到的，一层中的神经元只会连接到该层之前的一小部分区域，而不是以全连接的方式连接所有神经元。此外，CIFAR-10的最终输出层将具有1x1x10的尺寸，因为在ConvNet体系结构的末尾，我们会将整个图像缩小为沿着深度尺寸排列的单个类别评分数矢量。这是可视化效果：

![img](https://cs231n.github.io/assets/nn1/neural_net2.jpeg)

![img](https://cs231n.github.io/assets/cnn/cnn.jpeg)



参考：

https://cs231n.github.io/convolutional-networks/